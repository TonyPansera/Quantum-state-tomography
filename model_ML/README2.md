==============================
  SYNTHÃˆSE INTERNE DU PROJET
==============================
Dans la vraie vie, la tomographie quantique vise Ã  comparer l'Ã©tat idÃ©al que le scientifique essaye de fabriquer, avec l'Ã©tat rÃ©el.
Les mesures permettent de donner les mesures moyennes. Mais cela ne nous permet pas de recalculer directement les variables d'Ã©tat (theta et phi) par le calcul ( la relation que x = cos(theta)sin(phi) pour deux raisons : 
On utilise la mÃ©thode du MLE pour reconstruire l'Ã©tat Ã  partir des valeurs des mesures pour deux raisons : 
-le bruit statistique fait que les valeurs moyennes de X,Y et Z ne sont plus physiques, c'est Ã  dire X_chap^2 + Y_chap^2 + Z_chap^2 !=1. Le MLE prend Ã§a en compte, sinon les thÃªtas et phi seraiebnt incohÃ©rents.
- le relation n'Ã©tant pas linÃ©aire ( car sinusoÃ¯dale), on ne peut pas passer d'une valeur moyenne par transformation linÃ©aire. 
La tomograaphie quantique Ã  base de ML est un axe de recherche actuel, car Ã§a permet de passer outre ces problÃ©matiques, comme le MLE. 

ğŸ”¹ 1. Objectif global
Notre but est de comparer deux mÃ©thodes de reconstruction dâ€™Ã©tat pour un qubit :
   (a) la tomographie classique (MLE), 
   (b) la tomographie assistÃ©e par Machine Learning,
afin d'Ã©tudier :
   â€¢ la prÃ©cision,
   â€¢ la robustesse au bruit,
   â€¢ la dÃ©pendance au nombre de shots,
   â€¢ le coÃ»t computationnel.

Nous travaillons dâ€™abord sur le cas 1 qubit, avec possibilitÃ© dâ€™Ã©tendre Ã  plusieurs qubits plus tard 
(oÃ¹ le MLE devient trÃ¨s coÃ»teux).

------------------------------------------------------------

ğŸ”¹ 2. Notions cruciales : Ã©tat idÃ©al, Ã©tat rÃ©el, mesure bruitÃ©e
Dans notre simulation, il faut distinguer trois objets :

(1) Ã‰TAT IDÃ‰AL :
   - lâ€™Ã©tat pur que nous voulons prÃ©parer.
   - dÃ©fini par les paramÃ¨tres (Î¸, Ï†) sur la sphÃ¨re de Bloch.
   - vecteur de Bloch normÃ© : ||(X,Y,Z)|| = 1.

(2) Ã‰TAT RÃ‰EL :
   - lâ€™Ã©tat effectivement produit AVANT LES MESURES.
   - il peut Ãªtre :
       â†’ identique Ã  lâ€™Ã©tat idÃ©al (si aucun bruit physique mÃªme si il y a le bruit statistique ( car l'Ã©tat reste pure)),
       â†’ ou contractÃ© par un bruit physique simulÃ© (donc mixte).
   - câ€™est cet Ã©tat que les mÃ©thodes de tomographie cherchent Ã  reconstruire.

(3) MESURES BRUITÃ‰ES :
   - generated via tirages binomiaux Ã  partir des probabilitÃ©s de lâ€™Ã©tat rÃ©el.
   - bruit purement statistique : il ne modifie PAS lâ€™Ã©tat rÃ©el.

Ainsi :
   â€¢ le bruit physique transforme lâ€™Ã©tat rÃ©el,
   â€¢ le bruit statistique transforme uniquement les mesures,
   â€¢ le MLE/ML tente de retrouver lâ€™Ã©tat rÃ©el Ã  partir de ces mesures bruitÃ©es.

------------------------------------------------------------

ğŸ”¹ 3. Ce que signifie â€œÃ©tat rÃ©elâ€ dans notre projet

Cas A â€” PAS de bruit physique (seulement bruit statistique) :
   â†’ Ã©tat rÃ©el = Ã©tat idÃ©al (pur)
   â†’ les labels ML = (X_ideal, Y_ideal, Z_ideal)

Cas B â€” Bruit physique simulation par shrink anisotrope :
   â†’ Ã©tat rÃ©el = vecteur shrinkÃ© (X_real, Y_real, Z_real)
   â†’ il reste dans la sphÃ¨re de Bloch (physique)
   â†’ les labels ML = (X_real, Y_real, Z_real)

Dans les deux cas :
   â€¢ lâ€™Ã©tat rÃ©el est parfaitement dÃ©terminÃ© dans la simulation,
     mÃªme si le shrink est alÃ©atoire (une fois les paramÃ¨tres tirÃ©s, lâ€™Ã©tat est dÃ©fini).
   â€¢ les donnÃ©es de mesure ne sont jamais les labels : ce sont les features bruitÃ©es.

------------------------------------------------------------

ğŸ”¹ 4. Comment nous simulons le bruit physique (decoherence)

Nous utilisons un modÃ¨le â€œjouetâ€ mais cohÃ©rent :
   - avec probabilitÃ© = decoherence_level, lâ€™Ã©tat est bruitÃ©.
   - la contraction (shrink) appliquÃ©e sur (X,Y,Z) est :
         X_real = factor_X * X_ideal
         Y_real = factor_Y * Y_ideal
         Z_real = factor_Z * Z_ideal
   - oÃ¹ les factors sont gÃ©nÃ©rÃ©s Ã  partir de :
         base_factor = 1 - strength     (avec strength â‰¤ decoherence_level)
         anisotropy = tirage uniforme [0.5, 1.5]
         factors = clip(base_factor * anisotropy, 0, 1)
   - RÃ©sultat : lâ€™Ã©tat rÃ©el est une contraction anisotrope dans la sphÃ¨re de Bloch.

Ce bruit n'est pas un canal CPTP standard, mais :
   - il reste toujours PHYSIQUE,
   - il produit des Ã©tats mixtes cohÃ©rents (respectant x2+y2+z2â‰¤1),
   - il permet de tester la robustesse du ML,
   - il est contrÃ´lable par le paramÃ¨tre decoherence_level.

------------------------------------------------------------

ğŸ”¹ 5. Pourquoi on peut toujours rÃ©cupÃ©rer la valeur rÃ©elle

Parce que dans une simulation :
   - lâ€™Ã©tat rÃ©el est construit mathÃ©matiquement et sans ambiguÃ¯tÃ©.
   - mÃªme si les coefficients de shrink sont alÃ©atoires, 
     ils sont tirÃ©s UNE FOIS par Ã©chantillon â†’ Ã©tat dÃ©terministe.
   - lâ€™Ã©tat rÃ©el est donc EXACTEMENT connu pour chaque donnÃ©e du dataset.

Le bruit statistique nâ€™altÃ¨re jamais lâ€™Ã©tat rÃ©el : il ne touche que les mesures.
On peut donc utiliser (X_real, Y_real, Z_real) comme labels â€œparfaitsâ€.

------------------------------------------------------------

ğŸ”¹ 6. Ce que le modÃ¨le ML apprend rÃ©ellement

Le ML apprend :
   â€¢ Ã  reconstruire lâ€™Ã©tat rÃ©el (pur ou mixte),
   â€¢ Ã  partir des donnÃ©es de mesure bruitÃ©es,
   â€¢ exactement comme le ferait un estimateur statistique,
   â€¢ mais potentiellement plus vite ou avec moins de shots que le MLE.

Nous comparerons donc :
   - lâ€™erreur du MLE â‰ˆ distance entre Ï_MLE et Ï_real,
   - lâ€™erreur du ML â‰ˆ distance entre Ï_ML_pred et Ï_real.

------------------------------------------------------------

ğŸ”¹ 7. Workflow final pour le dataset

Pour chaque Ã©chantillon :

1. GÃ©nÃ©rer un Ã©tat idÃ©al (Î¸,Ï†).
2. Appliquer (ou pas) le bruit physique (shrink anisotrope) â†’ Ã©tat rÃ©el.
3. Calculer les probabilitÃ©s thÃ©oriques des mesures X/Y/Z.
4. Tirer n_shots mesures â†’ valeurs +1/-1 â†’ bruit statistique.
5. Extraire les features :
      (âŸ¨XâŸ©_mesurÃ©, âŸ¨YâŸ©_mesurÃ©, âŸ¨ZâŸ©_mesurÃ©)
6. DÃ©finir les labels = composantes de lâ€™Ã©tat rÃ©el :
      (X_real, Y_real, Z_real)

------------------------------------------------------------

ğŸ”¹ 8. En rÃ©sumÃ© 

- Lâ€™Ã©tat idÃ©al = on part de Ã§a pour contruire le dataset, mais il ne faut surtout pas l'utiliser directement pour entrainer le ML
- Lâ€™Ã©tat rÃ©el = ce qui existe physiquement aprÃ¨s bruit (ou Ã©gal Ã  lâ€™idÃ©al si aucun bruit physique).  
- Le ML doit apprendre lâ€™Ã©tat rÃ©el, pas lâ€™idÃ©al, pas le MLE.  
- Le shrink anisotrope est un bruit physique jouet mais valide.  
- Le bruit statistique ne change pas lâ€™Ã©tat, seulement les mesures.  
- Les labels = Ã©tat rÃ©el dÃ©terministe (pur ou mixte).  
- Nous comparons MLE vs ML pour reconstruire cet Ã©tat rÃ©el.  



# README â€” LAB0 & LAB1 : Dataset Exploration & Classification (SVC)

Ce document dÃ©crit les deux premiers Labs du projet :  
**Lab0 (exploration du dataset)** et **Lab1 (classification via SVC)**.  
Ils servent Ã  vÃ©rifier la validitÃ© physique des donnÃ©es, calibrer le pipeline, et Ã©tablir des benchmarks avant la tomographie machine learning.

---

# ğŸ¯ Objectifs gÃ©nÃ©raux des Labs 0 et 1

Ces deux Labs permettent de :

- **valider la gÃ©nÃ©ration du dataset**,  
- **explorer les propriÃ©tÃ©s des donnÃ©es** (plots, statistiques, bruit),  
- **comprendre le comportement des mesures X/Y/Z**,  
- **tester les kernels SVC comme premier benchmark ML**,  
- **vÃ©rifier que la chaÃ®ne expÃ©rimentale simulÃ©e fonctionne**,  
- **prÃ©parer les Labs de rÃ©gression**, qui rÃ©aliseront la vraie tomographie ML.

Ces Labs **ne reconstruisent pas encore lâ€™Ã©tat**.  
Ils servent de base de calibration, exactement comme dans un laboratoire.

---

# ğŸŸ§ LAB 0 â€” Exploration du Dataset

## ğŸ¯ Objectifs du Lab 0

1. VÃ©rifier que la fonction `generate_dataset` respecte les exigences physiques :
   - Ã©tat rÃ©el correctement dÃ©fini,
   - bruit statistique bien appliquÃ©,
   - shrink anisotrope gardant lâ€™Ã©tat physique,
   - labels cohÃ©rents avec lâ€™Ã©tat rÃ©el.

2. Comprendre visuellement la structure des donnÃ©es :
   - distributions,
   - effet du bruit statistique,
   - effet du shrink anisotrope,
   - structure dans lâ€™espace de Bloch.

3. Fournir des **plots explicatifs** utiles pour le rapport.

4. Sâ€™assurer que le dataset est **physiquement sain** avant dâ€™entraÃ®ner les modÃ¨les.

---
# LAB 1 â€” Classification (SVC & kernels)
## Clarification essentielle : ce que la classification ne peut pas faire

 La classification ne reconstruit pas lâ€™Ã©tat.
 Elle ne trouve pas (Î¸, Ï†).
 Elle nâ€™est pas une mÃ©thode de tomographie.
 Elle ne produit pas la matrice de densitÃ©.

Elle sert exclusivement Ã  reconnaitre une classe parmi un ensemble dâ€™Ã©tats discrets.

 Alors Ã  quoi sert la classification ?
 1. Benchmark simple pour tester les kernels

SVC permet de comparer :

kernel linÃ©aire

RBF

polynomial

QSVM (si intÃ©grÃ©)

2. VÃ©rifier la qualitÃ© du dataset

Si la classification Ã©choue â†’ problÃ¨me dans :

la simulation des mesures,

le bruit,

les features,

les labels.

3. Ã‰tudier la robustesse au bruit

On peut mesurer lâ€™impact :

du nombre de shots,

du shrink,

du niveau de dÃ©cohÃ©rence.

# RÃ©sumÃ©

Le Lab0 valide la physique du dataset (Ã©tat rÃ©el, shrink, bruit statistique).
Le Lab1 teste les kernels SVC sur une tÃ¢che simple de classification.

La classification nâ€™est PAS une forme de tomographie.
Elle ne sert pas Ã  trouver (Î¸, Ï†) ni Ã  reconstruire la matrice de densitÃ©.
Elle sert Ã  :
- valider le dataset,
- comparer les kernels classiques et quantiques,
- Ã©tudier lâ€™effet du bruit,
- prÃ©parer les Labs de rÃ©gression.

Les Labs suivants (Lab2 et Lab3) traiteront la vraie tomographie :
â†’ reconstruction du vecteur de Bloch rÃ©el avec ML,
â†’ comparaison directe ML vs MLE.