{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164ab1e6",
   "metadata": {},
   "source": [
    "# Notebook 2: Advanced Quantum Tomography\n",
    "## Deep Learning (DNN) & Variational Quantum Circuits (VQC) vs. Classical SVR\n",
    "\n",
    "## 1. Scientific Context & Exploration Goals\n",
    "In the previous notebook, we established a robust baseline using **Support Vector Regression (SVR)**, a classical kernel-based method. While effective, SVR relies on fixed kernels (RBF, Polynomial) which may not perfectly capture the complex geometry of quantum states under decoherence.\n",
    "\n",
    "In this second exploratory phase, we move towards **Advanced Architectures**. Our goal is to determine if models with higher representational capacity (Deep Learning) or native quantum priors (VQC) can surpass the classical baseline, particularly in the regime of **impure states (decoherence)** and **limited data**.\n",
    "\n",
    "We investigate two challengers:\n",
    "1.  **Deep Neural Networks (DNN):** Using the universal approximation theorem to model the mapping from measurements to density matrices with high non-linearity.\n",
    "2.  **Variational Quantum Circuits (VQC):** A \"Quantum Machine Learning\" approach. We hypothesize that a quantum circuit possesses a natural *inductive bias* for quantum data, potentially requiring fewer parameters to represent the Hilbert space than a classical network.\n",
    "\n",
    "## 2. A Paradigm Shift: \"Physics-Informed\" Training\n",
    "Unlike standard regression which minimizes the Euclidean distance (MSE), we introduce a **Custom Loss Function** grounded in Quantum Information Theory.\n",
    "\n",
    "### The \"Fidelity-Based\" Backpropagation\n",
    "Standard ML optimizes geometry. We want to optimize **physics**.\n",
    "Instead of blindingly minimizing $MSE = ||\\vec{r}_{pred} - \\vec{r}_{real}||^2$, we configure our Neural Networks (both Classical and Quantum) to directly maximize the **Quantum Fidelity** ($F$).\n",
    "\n",
    "During the **Backpropagation** pass, the gradient of the Fidelity is computed with respect to the model weights. This forces the optimizer to prioritize directions that increase the physical overlap between the predicted and true states.\n",
    "\n",
    "**The Mathematical Loss Function:**\n",
    "For a single qubit state defined by a Bloch vector $\\vec{r}$, the loss $\\mathcal{L}$ to minimize is:\n",
    "\n",
    "$$\\mathcal{L} = 1 - F(\\rho_{pred}, \\rho_{real})$$\n",
    "\n",
    "Where the Fidelity $F$ for single-qubit Bloch vectors is given analytically by:\n",
    "$$F(\\vec{r}_{p}, \\vec{r}_{t}) = \\frac{1}{2} \\left( 1 + \\vec{r}_{p} \\cdot \\vec{r}_{t} + \\sqrt{(1 - ||\\vec{r}_{p}||^2)(1 - ||\\vec{r}_{t}||^2)} \\right)$$\n",
    "\n",
    "* **Interpretation:** The term $\\vec{r}_{p} \\cdot \\vec{r}_{t}$ aligns the vectors directionally. The term under the square root penalizes errors in **purity** (vector length). This allows the DNN to specifically \"learn\" decoherence.\n",
    "\n",
    "## 3. Architecture Overview\n",
    "\n",
    "### A. Deep Neural Network (DNN - PyTorch)\n",
    "* **Structure:** A Multi-Layer Perceptron (MLP) with fully connected layers and non-linear activation functions (ReLU).\n",
    "* **Why:** To test if a \"Universal Approximator\" can learn the noise models better than fixed kernels.\n",
    "\n",
    "### B. Variational Quantum Circuit (VQC - PennyLane)\n",
    "* **Concept:** We use a parameterized quantum circuit as the model.\n",
    "* **Mechanism:**\n",
    "    1.  **Encoding:** Classical inputs ($X, Y, Z$) are embedded into a quantum state via rotation gates.\n",
    "    2.  **Processing:** A sequence of trainable gates (Ansatz) manipulates the state.\n",
    "    3.  **Measurement:** We measure the expectation values of Pauli operators to obtain the output vector.\n",
    "* **Hypothesis:** \"Quantum for Quantum\". A quantum circuit naturally evolves on the Bloch sphere (or inside it for mixed states via subsystems), which might offer better generalization with fewer parameters.\n",
    "\n",
    "## 4. Implementation: High-Performance Computing (GPU)\n",
    "With SVC, we had quite some long training time. So in order to handle the computational load of training deep networks and simulating quantum circuits, we leverage **GPU Acceleration**:\n",
    "* **PyTorch (CUDA/MPS):** For tensor operations and automatic differentiation of the DNN.\n",
    "* **PennyLane Lightning GPU:** Using high-performance state-vector simulators (like `lightning.gpu` or `lightning.qubit`) to accelerate the VQC simulation and gradient calculation (adjoint differentiation).\n",
    "\n",
    "We also do this as a way to learn modern high-performance ML pipelines.\n",
    "\n",
    "## 5. Input/Output Interfaces\n",
    "To ensure a rigorous comparison with the SVR baseline from Notebook 1, the I/O structure remains identical:\n",
    "\n",
    "* **Input $\\mathbf{X}$:** Noisy measurement expectations $[ \\langle X \\rangle_{noise}, \\langle Y \\rangle_{noise}, \\langle Z \\rangle_{noise} ]$.\n",
    "* **Output $\\mathbf{y}$:** Predicted Bloch vector components $[\\hat{x}, \\hat{y}, \\hat{z}]$.\n",
    "\n",
    "*Note: The predicted vector is implicitly constrained to valid physical states (norm $\\le$ 1) either via activation functions (Tanh) or penalty terms in the loss.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP GPU & DEVICE AGNOSTIC CODE\n",
    "# ==========================================\n",
    "def get_device():\n",
    "    \"\"\"Détecte automatiquement le meilleur accélérateur disponible.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # Pour les Mac M1/M2/M3 (Metal Performance Shaders)\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"✅ Computation Device: {DEVICE}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CUSTOM LOSS : QUANTUM FIDELITY\n",
    "# ==========================================\n",
    "class QuantumFidelityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Fonction de perte inversée : Loss = 1 - Fidélité.\n",
    "    Pousse le réseau à maximiser la superposition physique avec l'état cible.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(QuantumFidelityLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # y_pred, y_true shape: (batch_size, 3) correspondant à [X, Y, Z]\n",
    "        \n",
    "        # 1. Calcul des normes carrées (r^2)\n",
    "        # On clippe à 1.0 - epsilon pour éviter les racines de nombres négatifs\n",
    "        # si le réseau prédit temporairement un vecteur > 1.\n",
    "        r2_pred = torch.sum(y_pred**2, dim=1).clamp(max=1.0 - 1e-6)\n",
    "        r2_true = torch.sum(y_true**2, dim=1).clamp(max=1.0 - 1e-6)\n",
    "        \n",
    "        # 2. Produit scalaire (Orientation)\n",
    "        dot_prod = torch.sum(y_pred * y_true, dim=1)\n",
    "        \n",
    "        # 3. Terme de pureté (Grandeur)\n",
    "        # Formule : sqrt((1 - r_pred^2)(1 - r_true^2))\n",
    "        purity_term = torch.sqrt((1.0 - r2_pred) * (1.0 - r2_true))\n",
    "        \n",
    "        # 4. Fidélité\n",
    "        fidelity = 0.5 * (1.0 + dot_prod + purity_term)\n",
    "        \n",
    "        # 5. On retourne la perte moyenne (on veut minimiser 1 - F)\n",
    "        return (1.0 - fidelity).mean()\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL 1: DEEP NEURAL NETWORK (DNN)\n",
    "# ==========================================\n",
    "class TomographyDNN(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=64, output_dim=3):\n",
    "        super(TomographyDNN, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # Entrée : X_mean, Y_mean, Z_mean\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Sortie : X_pred, Y_pred, Z_pred\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            \n",
    "            # Tanh force la sortie entre [-1, 1], ce qui aide physiquement\n",
    "            # car une coordonnée de Bloch ne peut pas dépasser 1.\n",
    "            nn.Tanh() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL 2: VARIATIONAL QUANTUM CIRCUIT (VQC)\n",
    "# ==========================================\n",
    "# Configuration du simulateur quantique\n",
    "# 'lightning.qubit' est un simulateur C++ rapide pour CPU.\n",
    "# Pour le GPU 'vrai', il faut 'lightning.gpu' (voir explications plus bas).\n",
    "n_qubits = 4\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits) \n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"adjoint\")\n",
    "def quantum_circuit(inputs, weights):\n",
    "    \"\"\"\n",
    "    Circuit Variationnel.\n",
    "    inputs: Données classiques (Batch)\n",
    "    weights: Paramètres apprenables du circuit\n",
    "    \"\"\"\n",
    "    # 1. Encodage des données (Angle Embedding)\n",
    "    # On encode les features X, Y, Z dans les rotations des qubits\n",
    "    # On répète les inputs pour remplir les 4 qubits si nécessaire\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n",
    "    \n",
    "    # 2. Couches Variationnelles (Ansatz)\n",
    "    # StrongEntanglingLayers est très expressif pour apprendre des états complexes\n",
    "    qml.StrongEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    \n",
    "    # 3. Mesures : On veut 3 sorties (X, Y, Z)\n",
    "    # On mesure les espérances de Pauli sur les 3 premiers qubits pour récupérer 3 valeurs.\n",
    "    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))]\n",
    "\n",
    "class TomographyVQC(nn.Module):\n",
    "    def __init__(self, n_layers=3):\n",
    "        super(TomographyVQC, self).__init__()\n",
    "        \n",
    "        # Définition de la forme des poids pour StrongEntanglingLayers\n",
    "        weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
    "        \n",
    "        # qml.qnn.TorchLayer transforme le QNode PennyLane en une couche PyTorch standard !\n",
    "        self.q_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
    "        \n",
    "        # Optionnel : Une petite couche classique pour \"calibrer\" la sortie quantique\n",
    "        # Cela aide le VQC à mapper exactement vers l'espace de Bloch cible.\n",
    "        self.post_processing = nn.Linear(3, 3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # On passe dans le quantique\n",
    "        x_q = self.q_layer(x)\n",
    "        # On ajuste légèrement l'échelle\n",
    "        return torch.tanh(self.post_processing(x_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcf2fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m {\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      3\u001b[0m     {\n\u001b[0;32m      4\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m      6\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Notebook 2 \u001b[39m\u001b[38;5;130;01m\\u2014\u001b[39;00m\u001b[38;5;124m DNN vs VQC vs baseline\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoucle d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexploration pour comparer le DNN, le VQC et une baseline rapide (SVR/MLE approxim\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124me) en fonction du niveau de d\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mcoh\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mrence. Les classes `TomographyDNN`, `TomographyVQC` et `QuantumFidelityLoss` sont suppos\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mes d\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mj\u001b[39m\u001b[38;5;130;01m\\u00e0\u001b[39;00m\u001b[38;5;124m d\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mfinies dans la cellule pr\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mc\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mdente.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m       ]\n\u001b[0;32m     10\u001b[0m     },\n\u001b[0;32m     11\u001b[0m     {\n\u001b[0;32m     12\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m---> 14\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[0;32m     15\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m     16\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport time\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom torch.utils.data import DataLoader, TensorDataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom sklearn.model_selection import train_test_split\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport matplotlib.pyplot as plt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Import du g\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mrateur de dataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    from saint_dtSet import generate_qubit_tomography_dataset_base\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcept ImportError:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    from dataset_build.saint_dtSet import generate_qubit_tomography_dataset_base\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEVICE = torch.device(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m if torch.cuda.is_available() else \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.manual_seed(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.random.seed(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDevice: \u001b[39m\u001b[38;5;132;01m{DEVICE}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m       ]\n\u001b[0;32m     36\u001b[0m     },\n\u001b[0;32m     37\u001b[0m     {\n\u001b[0;32m     38\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m     40\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m     41\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m     42\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef fidelity_from_bloch(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Calcul analytique de la fid\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124m entre deux vecteurs de Bloch (qubit).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    pred et target: tensors (..., 3).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dot = (pred * target).sum(dim=-1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    norm_pred = (pred ** 2).sum(dim=-1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    norm_target = (target ** 2).sum(dim=-1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    under_sqrt = torch.clamp(1.0 - norm_pred, min=0.0) * torch.clamp(1.0 - norm_target, min=0.0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    fidelity = 0.5 * (1.0 + dot + torch.sqrt(under_sqrt))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return torch.clamp(fidelity, 0.0, 1.0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef build_dataloaders(df: pd.DataFrame, batch_size: int = 32):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    features = df[[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_mean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_mean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ_mean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]].to_numpy(dtype=np.float32)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    targets = df[[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_real\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_real\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ_real\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]].to_numpy(dtype=np.float32)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42, shuffle=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    test_ds = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return train_loader, test_loader, (X_test, y_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef evaluate_model(model, data_loader, device=DEVICE):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    model.eval()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    preds, targets = [], []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    with torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for xb, yb in data_loader:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            xb = xb.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            yb = yb.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            pred = model(xb)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            preds.append(pred.detach().cpu())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            targets.append(yb.detach().cpu())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    preds_t = torch.cat(preds, dim=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    targets_t = torch.cat(targets, dim=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    fidelities = fidelity_from_bloch(preds_t, targets_t)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return fidelities.mean().item()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef compute_baseline_fidelity(x_test: np.ndarray, y_test: np.ndarray) -> float:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Baseline rapide ~SVR/MLE : pr\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mdicteur trivial X_mean->X_real (sans contrainte de sph\u001b[39m\u001b[38;5;130;01m\\u00e8\u001b[39;00m\u001b[38;5;124mre).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    preds = torch.from_numpy(x_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    targets = torch.from_numpy(y_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return fidelity_from_bloch(preds, targets).mean().item()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m       ]\n\u001b[0;32m     91\u001b[0m     },\n\u001b[0;32m     92\u001b[0m     {\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m     96\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m     97\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef train_model(model, train_loader, optimizer, loss_fn, epochs: int, device=DEVICE):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Boucle g\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mrique d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentra\u001b[39m\u001b[38;5;130;01m\\u00ee\u001b[39;00m\u001b[38;5;124mnement.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    D\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mplace inputs/targets sur DEVICE avant forward comme demand\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    model.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    history = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for epoch in range(1, epochs + 1):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model.train()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        running_loss = 0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for xb, yb in train_loader:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            xb = xb.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            yb = yb.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            optimizer.zero_grad()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            preds = model(xb)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            loss = loss_fn(preds, yb)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            loss.backward()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            optimizer.step()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            running_loss += loss.item() * xb.size(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        epoch_loss = running_loss / len(train_loader.dataset)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        history.append(epoch_loss)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if epoch == 1 or epoch \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m max(1, epochs // 5) == 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{epoch:>3}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{epochs}\u001b[39;00m\u001b[38;5;124m - loss: \u001b[39m\u001b[38;5;132;01m{epoch_loss:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m       ]\n\u001b[0;32m    124\u001b[0m     },\n\u001b[0;32m    125\u001b[0m     {\n\u001b[0;32m    126\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    127\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    128\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    129\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    130\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# ---------------------------------------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Boucle d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mrimentation principale\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# ---------------------------------------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN_STATES = 2000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN_SHOTS = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDECOHERENCE_LEVELS = [0.0, 0.2, 0.5, 0.8]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH_SIZE = 32\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS_DNN = 25\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS_VQC = 12  # VQC plus lent -> moins d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR_DNN = 0.01\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR_VQC = 0.05\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mdnn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [], \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mvqc\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [], \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: []}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor level in DECOHERENCE_LEVELS:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== D\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mcoh\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mrence \u001b[39m\u001b[38;5;132;01m{level}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    df = generate_qubit_tomography_dataset_base(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        n_states=N_STATES,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        n_shots=N_SHOTS,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        include_decoherence=True,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoherence_level=level,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mode=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mfinite_shots\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        random_state=1234\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    train_loader, test_loader, (x_test, y_test) = build_dataloaders(df, batch_size=BATCH_SIZE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # ---------------------- DNN ----------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dnn = TomographyDNN().to(DEVICE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dnn_optimizer = torch.optim.Adam(dnn.parameters(), lr=LR_DNN)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dnn_loss = QuantumFidelityLoss()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    _ = train_model(dnn, train_loader, dnn_optimizer, dnn_loss, epochs=EPOCHS_DNN, device=DEVICE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dnn_fid = evaluate_model(dnn, test_loader, device=DEVICE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # ---------------------- VQC ----------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    vqc = TomographyVQC().to(DEVICE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    vqc_optimizer = torch.optim.Adam(vqc.parameters(), lr=LR_VQC)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    vqc_loss = QuantumFidelityLoss()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    _ = train_model(vqc, train_loader, vqc_optimizer, vqc_loss, epochs=EPOCHS_VQC, device=DEVICE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    vqc_fid = evaluate_model(vqc, test_loader, device=DEVICE)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # -------------------- Baseline --------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    baseline_fid = compute_baseline_fidelity(x_test, y_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    results[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mdnn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m].append(dnn_fid)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    results[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mvqc\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m].append(vqc_fid)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    results[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m].append(baseline_fid)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDNN fidelity (test): \u001b[39m\u001b[38;5;132;01m{dnn_fid:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mVQC fidelity (test): \u001b[39m\u001b[38;5;132;01m{vqc_fid:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBaseline fidelity    : \u001b[39m\u001b[38;5;132;01m{baseline_fid:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoucle termin\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124me.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m       ]\n\u001b[0;32m    186\u001b[0m     },\n\u001b[0;32m    187\u001b[0m     {\n\u001b[0;32m    188\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    189\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    190\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    191\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    192\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Visualisation des fid\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124ms moyennes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.figure(figsize=(8, 5))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.plot(DECOHERENCE_LEVELS, results[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdnn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNN\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.plot(DECOHERENCE_LEVELS, results[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvqc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVQC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.plot(DECOHERENCE_LEVELS, results[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline (SVR/MLE rapide)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.xlabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNiveau de d\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mcoh\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mrence\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.ylabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFid\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;130;01m\\u00e9\u001b[39;00m\u001b[38;5;124m moyenne (test)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.ylim(0.0, 1.05)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.grid(True, alpha=0.3)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.legend()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m       ]\n\u001b[0;32m    205\u001b[0m     }\n\u001b[0;32m    206\u001b[0m   ],\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    209\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m     },\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    214\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    217\u001b[0m       },\n\u001b[0;32m    218\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.11.9\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m     }\n\u001b[0;32m    225\u001b[0m   },\n\u001b[0;32m    226\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m    227\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m    228\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
